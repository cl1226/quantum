spark {
  spark.app.name = "mysql2hive"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"
}

input {
  sqlserver {
    result_table_name = "source"
    url = "jdbc:sqlserver://10.36.30.22:1433;DatabaseName=SVOLT20220325"
    database = "SVOLT20220325"
    user = "dpd"
    password = "dpd@123"
    tableName = "PLAN_WORK_ORDER"
    driver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"
    readMode = "full"
    partColumnName = "OrderCode"
    numPartitions = 5
  }
}

transform {

}

output {
  clickhouse {
    host = "node05:8123"
    clickhouse.socket_timeout = 50000
    database = "svolt"
    table = "PLAN_WORK_ORDER_DISTRIBUTE"
    #fields = ["Id", "OrderCode", "ProductId", "FactoryId", "WorkCenterId", "ProcessRouteId", "ProductBOMId"]
    username = "default"
    password = "clickhouse"
    bulk_size = 20000
  }
}

